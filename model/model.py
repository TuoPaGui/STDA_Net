import numpy as np
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import copy
from copy import deepcopy
import math
import flash_attention
import torch.distributions as dist
from torch.nn.utils import spectral_norm
from kymatio.torch import Scattering1D
import random

from torchaudio.compliance.kaldi import spectrogram
from torchdiffeq import odeint
from torch_geometric.nn import GCNConv
from torch_geometric.data import Batch, Data
import torch.nn.init as init
import librosa.display
import librosa
import itertools
from collections import OrderedDict

# å¯è§†åŒ–
import matplotlib.pyplot as plt
from tensorflow.python.tools.optimize_for_inference_lib import INPUT_ORDER
import seaborn as sns

############################################ é¢‘è°±è½¬æ¢ ############################################
class SpectrogramTransform(nn.Module):
    def __init__(self, Fs=100,n_fft=256, hop_length=100, window_fn=torch.hamming_window,max_freq=30,):
        super(SpectrogramTransform, self).__init__()
        self.Fs = Fs
        self.n_fft = n_fft
        self.hop_length = hop_length
        self.window = window_fn(n_fft)

        self.max_freq = max_freq

    def forward(self, data):
        # è¾“å…¥å½¢çŠ¶: (batch_size, num_channels, time_steps)
        batch_size, num_channels, _ = data.shape
        # è°ƒæ•´å½¢çŠ¶ä¸º (batch_size*num_channels, time_steps)
        input_reshaped = data.view(batch_size * num_channels, -1)
        # å°†çª—å‡½æ•°ç§»åŠ¨åˆ°è®¾å¤‡ä¸Šï¼Œå¦‚æœè¾“å…¥æ•°æ®åœ¨GPUä¸Š
        window = self.window.to(data.device)

        # è®¡ç®—STFT
        spec = torch.stft(input_reshaped, n_fft=self.n_fft,
                          hop_length=self.hop_length,
                          window=window, center=True, normalized=True,
                          onesided=True, return_complex=True)

        # æ–°å¢é¢‘ç‡æˆªæ–­é€»è¾‘
        freq_resolution = self.Fs / self.n_fft  # é¢‘ç‡åˆ†è¾¨ç‡
        max_freq_bin = int(self.max_freq // freq_resolution)  # æœ€å¤§é¢‘ç‡å¯¹åº”çš„binç´¢å¼•
        max_freq_bin = min(max_freq_bin, spec.size(1)-1)  # é˜²æ­¢è¶…å‡ºèŒƒå›´
        # æˆªæ–­é¢‘ç‡èŒƒå›´ (0-max_freq Hz)
        spec = spec[:, :max_freq_bin+1, :]  # ä¿ç•™åˆ°max_freq_binçš„é¢‘ç‡ç‚¹

        spec_power = torch.abs(spec) ** 2  # è®¡ç®—åŠŸç‡è°±
        spec_abs = spec_power

        # å¯¹æ•°å°ºåº¦å˜æ¢
        spec_abs = torch.log10(spec_abs + 1e-9)  # åŠ ä¸€ä¸ªå°é‡é˜²æ­¢ log(0)

        # é€æ ·æœ¬é€é€šé“æ ‡å‡†åŒ–
        mean = spec_abs.mean(dim=(1, 2), keepdim=True)  # (batch*channels, 1, 1)
        std = spec_abs.std(dim=(1, 2), keepdim=True) + 1e-9
        spec_abs = (spec_abs - mean) / std

        # è°ƒæ•´å½¢çŠ¶å¹¶è½¬ç½®ç»´åº¦
        spec_abs = spec_abs.view(batch_size, num_channels, spec_abs.size(1), spec_abs.size(2))
        spec_abs = spec_abs.transpose(2, 3)  # (batch, channels, time, freq)

        return spec_abs

class PhysioGuidedEnhancer(nn.Module):
    def __init__(self, num_channels, num_filters, band_range, freq_res, num_bins):
        super().__init__()
        self.num_channels = num_channels
        self.num_filters = num_filters
        self.freq_res = freq_res
        self.num_bins = num_bins
        f_start, f_end = band_range

        center_pos = torch.linspace(f_start, f_end, num_filters) / freq_res
        center_pos = center_pos.view(1, num_filters, 1)
        self.raw_centers = nn.Parameter(center_pos.repeat(num_channels, 1, 1))

        std_val = ((f_end - f_start) / num_filters) / freq_res
        self.widths = nn.Parameter(torch.full((num_channels, num_filters, 1), std_val))

        # å¯å­¦ä¹ é¢‘å¸¦å¢å¼ºç³»æ•°ï¼ˆæ¯ä¸ªæ»¤æ³¢å™¨ï¼‰
        self.gains = nn.Parameter(torch.ones(num_channels, num_filters, 1))

        self.register_buffer('freqs', torch.arange(num_bins).float().view(1, 1, num_bins))

    def forward(self, spec_slice, freq_offset):
        # è®¡ç®—æ¯ä¸ªæ»¤æ³¢å™¨çš„ä¸­å¿ƒä½ç½® muï¼ˆsoftplus ä¿è¯æ­£å€¼ï¼Œå†åŠ ä¸Šå½“å‰é¢‘æ®µçš„èµ·å§‹ bin åç§»ï¼‰
        mu = F.softplus(self.raw_centers) + freq_offset

        # è®¡ç®—æ¯ä¸ªæ»¤æ³¢å™¨çš„å®½åº¦ stdï¼ˆsoftplus ä¿è¯æ­£ï¼Œ+1e-3 é˜²æ­¢ä¸º 0ï¼‰
        std = F.softplus(self.widths) + 1e-3

        # é™åˆ¶ä¸­å¿ƒ mu åœ¨å½“å‰é¢‘æ®µèŒƒå›´å†…
        mu = mu.clamp(freq_offset, freq_offset + self.freqs.shape[-1] - 1)
        # é™åˆ¶å®½åº¦ stdï¼Œé¿å…è¿‡çª„æˆ–è¿‡å®½ï¼ˆä¸‹é™ 0.5ï¼Œä¸Šé™çº¦ä¸ºè¯¥é¢‘æ®µé•¿åº¦/æ»¤æ³¢å™¨æ•°çš„ä¸¤å€ï¼‰
        std = std.clamp(0.5, 2 * self.freqs.shape[-1] / self.num_filters)
        # ç”Ÿæˆé«˜æ–¯æƒé‡æ›²çº¿ï¼Œæ¯ä¸ª (é€šé“, æ»¤æ³¢å™¨) å¯¹åº”ä¸€æ¡é•¿åº¦ F çš„æ›²çº¿
        gauss = torch.exp(-0.5 * ((self.freqs - mu) / std) ** 2)  # [C, N, F]
        # å¯¹æ¯æ¡æ›²çº¿åœ¨é¢‘ç‡ç»´åº¦å½’ä¸€åŒ–ï¼Œä½¿æƒé‡å’Œä¸º 1
        # åœ¨é¢‘ç‡ç»´åº¦
        # F ä¸Šå½’ä¸€åŒ–ä¹‹åï¼Œæ¯æ¡æ»¤æ³¢å™¨æ›²çº¿çš„ æ‰€æœ‰ç‚¹åŠ èµ·æ¥ = 1ã€‚
        # è¿™æ—¶ï¼Œæ›²çº¿çš„å³°å€¼é«˜åº¦ä¸å†å›ºå®šä¸º 1ï¼Œè€Œæ˜¯å–å†³äº stdï¼š
        # std å¤§ï¼ˆæ›²çº¿å®½ï¼‰ â†’ å³°å€¼ä¼šå¾ˆä½ï¼ˆå› ä¸ºè¦åˆ†å¸ƒåˆ°å¾ˆå¤šç‚¹ä¸Šï¼‰ã€‚
        weights = gauss / (gauss.sum(dim=-1, keepdim=True) + 1e-6)
        # ä¹˜ä»¥å¯å­¦ä¹ çš„å¢å¼ºç³»æ•° gainsï¼ˆæ§åˆ¶æ¯ä¸ªæ»¤æ³¢å™¨æ•´ä½“å¼ºåº¦ï¼‰ å½¢çŠ¶: [C, N, F]
        weights = self.gains * weights  # åŠ æƒå¢å¼º
        # æŒ‰ç…§æƒé‡åœ¨é¢‘ç‡ç»´åº¦åŠ æƒæ±‚å’Œï¼ŒæŠŠ [B, C, T, F] å‹ç¼©åˆ° [B, C, T, N]
        return torch.einsum('bctf,cnf->bctn', spec_slice, weights)

class CrossBandSpatialAttention(nn.Module):
    def __init__(self, num_bands=6, num_channels=3, reduction=4):
        super().__init__()
        inter_channels = num_channels * 2
        self.fc1 = nn.Conv2d(num_bands * num_channels, inter_channels, 1)
        self.act = nn.GELU()
        self.fc2 = nn.Conv2d(inter_channels, num_bands * num_channels, 1)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, feats):  # feats: [B, band, C, T, F]
        B, band, C, T, Freq = feats.shape
        x = feats.view(B, band * C, T, Freq)
        attn = self.fc2(self.act(self.fc1(x)))
        attn = self.softmax(attn.view(B, band, C, T, Freq))
        return attn

class SleepBandEnhancerPlusPlus(nn.Module):
    """
    å…³é”®æ”¹åŠ¨ï¼š
      1) å»é™¤â€œå…ˆæ’å€¼åˆ°å„è‡ª F_band å†å¯¹é½åˆ° max_f_bandâ€çš„æµç¨‹ï¼›
         ç°åœ¨ï¼šå„é¢‘æ®µå…ˆå‹åˆ°å›ºå®š N=num_filtersï¼ˆæœ¬å°±å›ºå®šï¼‰ï¼Œç›´æ¥åšè·¨é¢‘å¸¦æ³¨æ„åŠ›ã€‚
      2) é‡å»ºé˜¶æ®µæŒ‰æ¯æ®µåŸå§‹ f_len è¿˜åŸï¼šé»˜è®¤ 'linear'ï¼ˆé€ä½ç½®çº¿æ€§å±‚ï¼Œç­‰ä»·é¢‘åŸŸ 1x1 å·ç§¯ï¼‰ï¼›
         å¯é€‰ 'interp'ï¼ˆåŒçº¿æ€§æ’å€¼ï¼‰ä»¥ä¾¿å¿«é€Ÿå¯¹æ¯”ã€‚
      3) ä¿®å¤äº†é«˜æ–¯ä¸­å¿ƒåæ ‡ä½“ç³»ï¼Œé¿å…ç»å¯¹/ç›¸å¯¹åæ ‡æ··ç”¨ã€‚
    """
    def __init__(self, num_channels=3, freq_bins=103, Fs=100, n_fft=256,
                 num_filters=6, reconstruct_mode: str = 'interp'):
        """
        reconstruct_mode: 'linear' | 'interp'
           - 'linear': æ¯é¢‘æ®µä½¿ç”¨ nn.Linear(num_filters -> f_len) å­¦ä¹ å¼è¿˜åŸï¼ˆé»˜è®¤ï¼‰
           - 'interp'ï¼šä½¿ç”¨æ’å€¼è¿˜åŸï¼ˆä¾¿äºåš ablationï¼‰
        """
        super().__init__()
        self.freq_res = Fs / n_fft
        self.num_channels = num_channels
        self.freq_bins = freq_bins
        self.num_filters = num_filters
        assert reconstruct_mode in ('linear', 'interp')
        self.reconstruct_mode = reconstruct_mode

        self.band_cfg = OrderedDict([
            ('delta', (0.5, 4)),
            ('theta', (4, 8)),
            ('alpha', (8, 12)),
            ('sigma', (12, 16)),
            ('beta1', (16, 24)),
            ('beta2', (24, 30))
        ])

        self.branches = nn.ModuleDict()
        self.align_convs = nn.ModuleDict()
        self.reconstructors = nn.ModuleDict()  # ä»…åœ¨ linear æ¨¡å¼ä¸‹ç”¨
        self.band_order = []

        for name, (f_start, f_end) in self.band_cfg.items():
            start_bin = int(f_start / self.freq_res)
            end_bin = int(f_end / self.freq_res)
            num_bins = end_bin - start_bin + 1

            # é¢‘æ®µå†…çš„ç”Ÿç†å¼•å¯¼å¢å¼ºï¼ˆè¾“å‡ºæœ€åä¸€ç»´ä¸º N=num_filtersï¼‰
            self.branches[name] = PhysioGuidedEnhancer(
                num_channels, num_filters, (f_start, f_end), self.freq_res, num_bins
            )
            # é€šé“å¯¹é½ï¼ˆä¸æ”¹ H=W å½¢çŠ¶ï¼‰
            self.align_convs[name] = nn.Conv2d(num_channels, num_channels, kernel_size=1)

            # çº¿æ€§é‡å»ºï¼šN -> f_lenï¼ˆæ¯æ®µå„è‡ªçš„ f_lenï¼‰
            if self.reconstruct_mode == 'linear':
                self.reconstructors[name] = nn.Linear(num_filters, num_bins, bias=True)

            self.band_order.append((name, start_bin, end_bin))

        self.cross_attn = CrossBandSpatialAttention(
            num_bands=len(self.band_cfg), num_channels=num_channels
        )

        # æ¯ä¸ªé¢‘æ®µæ•´ä½“æƒé‡ï¼ˆband-level gainï¼‰
        self.band_gain = nn.Parameter(torch.ones(len(self.band_order)))

        self.gate = nn.Sequential(
            nn.Conv2d(num_channels, num_channels, 1),
            nn.Sigmoid()
        )

        self.proj = nn.Sequential(
            nn.Conv2d(num_channels, num_channels, 1),
            nn.BatchNorm2d(num_channels),
            nn.GELU()
        )

    def forward(self, spec):  # spec: [B, C, T, F]   e.g., [256, 4, 31, 77]
        B, C, T, Freq = spec.shape
        band_feats = []  # æ¯æ®µå½¢çŠ¶ï¼š[B, C, T, N=num_filters]

        # 1) é€é¢‘æ®µï¼šè£å‰ª -> å¢å¼º -> é€šé“å¯¹é½ï¼›ä¸å†æ’å€¼åˆ° f_len
        for name, start_bin, end_bin in self.band_order:
            sliced = spec[:, :, :, start_bin:end_bin + 1]                  # [B, C, T, f_len]
            filtered = self.branches[name](sliced, start_bin)              # [B, C, T, N]
            aligned = self.align_convs[name](filtered)                     # [B, C, T, N]
            band_feats.append(aligned)

        # 2) è·¨é¢‘å¸¦æ³¨æ„åŠ›ï¼ˆåœ¨ band ç»´ softmaxï¼‰ï¼Œæœ€åä¸€ç»´ä¸ºå›ºå®š N=num_filters
        #    stack åå½¢çŠ¶ï¼š[B, num_bands, C, T, N]
        band_stack = torch.stack(band_feats, dim=1)
        attn_weights = self.cross_attn(band_stack)
        band_stack = band_stack * attn_weights * self.band_gain.view(1, -1, 1, 1, 1)

        # 3) é‡å»ºåˆ°åŸå§‹é¢‘è½´ï¼šå¯¹æ¯æ®µä» N -> f_lenï¼Œå†å†™å›å„è‡ª [start:end]
        enhanced = torch.zeros(B, C, T, Freq, device=spec.device, dtype=spec.dtype)

        for i, (name, start_bin, end_bin) in enumerate(self.band_order):
            f_len = end_bin - start_bin + 1
            narrow = band_stack[:, i]  # [B, C, T, N]

            if self.reconstruct_mode == 'linear':
                # é€ä½ç½®çº¿æ€§æ˜ å°„ï¼ˆç­‰ä»·äºé¢‘åŸŸ 1Ã—1 å·ç§¯ï¼‰ï¼Œå­¦ä¹ å¼è¿˜åŸåˆ° f_len
                y = narrow.reshape(B * C * T, self.num_filters)                  # [BCT, N]
                y = self.reconstructors[name](y)                                 # [BCT, f_len]
                band_feat = y.view(B, C, T, f_len)                               # [B, C, T, f_len]
            else:
                # æ’å€¼è¿˜åŸï¼šN -> f_len
                band_feat = F.interpolate(narrow, size=(T, f_len),
                                          mode='bilinear', align_corners=False)  # [B, C, T, f_len]

            enhanced[:, :, :, start_bin:end_bin + 1] += band_feat

        # 4) æ®‹å·®é—¨æ§èåˆ + æŠ•å½±
        residual = enhanced - spec
        enhanced = spec + self.gate(residual)*residual
        return self.proj(enhanced)


class Spectral_Enhancement(nn.Module):
    def __init__(self, num_channels=4, pool_size=(64, 64)):
        super(Spectral_Enhancement, self).__init__()

        # STFT å˜æ¢
        self.spectrogram = SpectrogramTransform()

        self.filterbank = SleepBandEnhancerPlusPlus(num_channels=num_channels)

        self.norm = nn.BatchNorm2d(num_channels)

    def forward(self, x):

        # STFTå˜æ¢
        spec = self.spectrogram(x)
        # é¢‘å¸¦è‡ªé€‚åº”å¢å¼º
        spec = self.filterbank(spec)

        return spec

# åŠ¨æ€å·ç§¯
class DynamicKernelConv2D(nn.Module):
    def __init__(self, in_channels, out_channels, max_kernel_size=(7, 7), stride=1,
                 use_bn=True, use_act=True):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.max_kernel = max_kernel_size
        self.stride = stride
        self.use_bn = use_bn
        self.use_act = use_act

        # é™æ€æƒé‡ï¼šæ‰€æœ‰æ ·æœ¬å…±äº«
        self.weight = nn.Parameter(
            torch.randn(out_channels, in_channels, *max_kernel_size)
        )
        self.bias = nn.Parameter(torch.zeros(out_channels))

        # åŠ¨æ€å‚æ•°é¢„æµ‹ç½‘ç»œï¼šæ ¹æ®è¾“å…¥ç‰¹å¾ç”Ÿæˆæ©æ¨¡å‚æ•°
        self.param_predictor = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),  # ä»æ•´ä¸ªç‰¹å¾å›¾æå–å…¨å±€ä¿¡æ¯
            nn.Flatten(),
            nn.Linear(in_channels, 3),  # è¾“å‡º alpha_h, alpha_w, sigma
        )

        if self.use_bn:
            self.bn = nn.BatchNorm2d(out_channels)
        if self.use_act:
            self.act = nn.GELU()

    def generate_gaussian_mask(self, kernel_size, center_h, center_w, sigma, device):
        H, W = kernel_size
        y = torch.linspace(0, 1, steps=H, device=device).unsqueeze(1).repeat(1, W)
        x = torch.linspace(0, 1, steps=W, device=device).unsqueeze(0).repeat(H, 1)
        # æ¯ä¸ªæ‰¹æ¬¡æ ·æœ¬çš„å‚æ•°éƒ½ä¸åŒ
        gauss = torch.exp(-((x - center_w) ** 2 + (y - center_h) ** 2) / (2 * sigma ** 2))
        return gauss  # å½¢çŠ¶: [B, H, W]

    def forward(self, x):
        B, C, H, W = x.shape
        device = x.device

        # 1. åŠ¨æ€é¢„æµ‹æ©æ¨¡å‚æ•°
        params = self.param_predictor(x)
        alpha_h = F.sigmoid(params[:, 0]).view(B, 1, 1)  # å½’ä¸€åŒ–åˆ° (0,1)
        alpha_w = F.sigmoid(params[:, 1]).view(B, 1, 1)
        sigma = F.softplus(params[:, 2]).view(B, 1, 1) + 1e-3  # ä¿è¯æ­£æ•°

        # 2. æ ¹æ®åŠ¨æ€å‚æ•°ç”Ÿæˆæ©æ¨¡
        # æ¯ä¸ªæ‰¹æ¬¡æ ·æœ¬éƒ½æœ‰ä¸€ä¸ªç‹¬ç«‹çš„æ©æ¨¡
        mask2d = self.generate_gaussian_mask(
            self.max_kernel, alpha_h, alpha_w, sigma, device=device
        ).unsqueeze(1).unsqueeze(1)  # å½¢çŠ¶: [B, 1, 1, H, W]

        # 3. å°†é™æ€æƒé‡ä¸åŠ¨æ€æ©æ¨¡èåˆ
        # è¿™ä¸€æ­¥æ˜¯å…³é”®ï¼Œå°†æ‰¹æ¬¡ç»´åº¦çš„æ©æ¨¡åº”ç”¨åˆ°å…±äº«çš„æƒé‡ä¸Š
        # ğŸ’¡ ä½¿ç”¨ unsqueeze(0) å’Œå¹¿æ’­æ¥ç”Ÿæˆæ‰¹æ¬¡ç»´åº¦çš„åŠ¨æ€æƒé‡
        weight_dynamic = self.weight.unsqueeze(0) * mask2d  # å½¢çŠ¶: [B, O, I, H, W]

        pad_h = self.max_kernel[0] // 2
        pad_w = self.max_kernel[1] // 2

        # 4. æ‰§è¡Œå·ç§¯æ“ä½œ
        # ç”±äº F.conv2d ä¸æ”¯æŒæ‰¹æ¬¡ç»´åº¦çš„æƒé‡ï¼Œæˆ‘ä»¬ä½¿ç”¨ `groups` å‚æ•°æ¥æ¨¡æ‹Ÿ
        # å…³é”®: å°†è¾“å…¥ x çš„æ‰¹æ¬¡ç»´åº¦å’Œé€šé“ç»´åº¦åˆå¹¶
        conv_out = F.conv2d(
            x.view(1, B * C, H, W),
            weight_dynamic.view(B * self.out_channels, C, *self.max_kernel),
            bias=self.bias.repeat(B),
            stride=self.stride,
            padding=(self.max_kernel[0] // 2, self.max_kernel[1] // 2),
            groups=B
        )
        # ç°åœ¨ conv_out å·²ç»è¢«æ­£ç¡®èµ‹å€¼äº†
        out = conv_out.view(B, self.out_channels, conv_out.shape[2], conv_out.shape[3])

        # 5. åº”ç”¨ BN å’Œæ¿€æ´»å‡½æ•°
        if self.use_bn:
            out = self.bn(out)
        if self.use_act:
            out = self.act(out)
        return out

class TransformerFusion(nn.Module):
    def __init__(self, in_channels=256, embed_dim=100, num_heads=5, num_layers=2, dropout=0.1):
        super().__init__()
        assert embed_dim % num_heads == 0, "embed_dim must be divisible by num_heads"
        self.project = nn.Conv2d(in_channels, embed_dim, kernel_size=1)

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim,
            nhead=num_heads,
            dim_feedforward=embed_dim * 4,
            dropout=dropout,
            batch_first=True
        )
        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.norm = nn.LayerNorm(embed_dim)
        self.dropout = nn.Dropout2d(dropout)

    def forward(self, x):  # x: [B, C, H, W]
        B, C, H, W = x.shape
        x = self.project(x)                     # [B, embed_dim, H, W]
        x = x.flatten(2).transpose(1, 2)        # [B, H*W, embed_dim]
        x = self.encoder(x)                     # [B, H*W, embed_dim]
        x = self.norm(x)
        x = x.transpose(1, 2).view(B, -1, H, W) # [B, embed_dim, H, W]
        return self.dropout(x)

class DAMS_CNN(nn.Module):
    def __init__(self, in_channels=4, drate=0.5):
        super(DAMS_CNN, self).__init__()

        # å°æ„Ÿå—é‡åˆ†æ”¯
        self.features1 = nn.Sequential(
            DynamicKernelConv2D(in_channels, 64, max_kernel_size=(4, 7), stride=1),
            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),  # (31,77) -> (15,38)
            nn.Dropout2d(drate),

            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=1, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.GELU(),

            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=1, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.GELU(),

            nn.MaxPool2d(kernel_size=(2, 2), stride=(1, 2))  # ç¨å¾®å‹ç¼©é¢‘åŸŸ
        )

        # å¤§æ„Ÿå—é‡åˆ†æ”¯
        self.features2 = nn.Sequential(
            DynamicKernelConv2D(in_channels, 64, max_kernel_size=(8, 13), stride=2),
            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),  # (15,38) -> (7,19)
            nn.Dropout2d(drate),

            nn.Conv2d(64, 128, kernel_size=(3, 9), stride=1, padding=(1, 4), bias=False),
            nn.BatchNorm2d(128),
            nn.GELU(),

            nn.Conv2d(128, 128, kernel_size=(1, 5), stride=1, padding=(0, 2), bias=False),
            nn.BatchNorm2d(128),
            nn.GELU(),

            nn.MaxPool2d(kernel_size=(2, 2), stride=(1, 1))  # æ§åˆ¶ä¸‹é‡‡æ ·é€Ÿç‡
        )

        # èåˆï¼šæ‹¼æ¥ + é€šé“æ³¨æ„åŠ›
        self.fusion = TransformerFusion(in_channels=256, embed_dim=100, num_heads=5)

    def forward(self, x):  # x: (B, 4, 31, 103)

        x1 = self.features1(x)  # (B, 128, H1, W1)
        x2 = self.features2(x)  # (B, 128, H2, W2)

        # å¯¹é½ç©ºé—´å¤§å°
        if x1.shape[2:] != x2.shape[2:]:
            target_size = (min(x1.shape[2], x2.shape[2]), min(x1.shape[3], x2.shape[3]))
            x1 = F.adaptive_avg_pool2d(x1, target_size)
            x2 = F.adaptive_avg_pool2d(x2, target_size)

        x_fused = torch.cat([x1, x2], dim=1)  # [B, 256, H, W]
        x_fused = self.fusion(x_fused)        # [B, 128, H, W]

        return x_fused

################################################ æ®‹å·®å› æœTCN ###################################################
class ResidualTCNBlock(nn.Module):
    def __init__(self, d_model, kernel_size, dilation, dropout=0.3, expansion=2, causal=False):
        super().__init__()
        hidden_dim = d_model * expansion
        self.causal = causal

        if causal:
            self.padding = (kernel_size - 1) * dilation
            self.pad = nn.ConstantPad1d((self.padding, 0), 0)  # åªåœ¨å·¦ä¾§ pad
        else:
            self.padding = ((kernel_size - 1) * dilation) // 2
            self.pad = nn.ConstantPad1d((self.padding, self.padding), 0)  # åŒå‘ padï¼ˆsame paddingï¼‰

        self.block = nn.Sequential(
            self.pad,
            nn.Conv1d(d_model, hidden_dim, kernel_size, dilation=dilation),
            nn.GELU(),
            nn.Conv1d(hidden_dim, d_model, kernel_size=1),
            nn.Dropout(dropout),
            nn.GELU(),
        )

        self.norm = nn.LayerNorm(d_model)

    def forward(self, x):
        residual = x
        out = self.block(x)
        out = out + residual
        out = self.norm(out.transpose(1, 2)).transpose(1, 2)
        return out

class TemporalTCNBlock(nn.Module):
    def __init__(self, d_model=100, levels=4, kernel_size=3, dropout=0.3, causal=False):
        super().__init__()
        self.network = nn.Sequential(*[
            ResidualTCNBlock(d_model, kernel_size, dilation=2 ** i, dropout=dropout, causal=causal)
            for i in range(levels)
        ])

    def forward(self, x):  # x: [B, T, D]
        x = x.transpose(1, 2)  # [B, D, T]
        x = self.network(x)
        x = x.transpose(1, 2)  # [B, T, D]
        return x

# Attention-Guided global-local encoder
class AGLE(nn.Module):
    def __init__(self, d_model=128, dropout=0.3, n_heads=4, use_layerscale=False, causal=False):
        super().__init__()
        self.d_model = d_model
        self.use_layerscale = use_layerscale
        self.causal = causal

        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)

        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=n_heads, dropout=dropout, batch_first=True)
        self.tcn = TemporalTCNBlock(d_model=d_model, dropout=dropout, causal=causal)

        # å¢å¼º gate çš„è¡¨è¾¾èƒ½åŠ›ã€ä¿è¯è®­ç»ƒç¨³å®šæ€§ï¼Œæœ€ç»ˆç”Ÿæˆä¸€ä¸ªæ›´æœ‰æ•ˆã€æ›´å¯æ§çš„åŠ¨æ€é—¨æ§ä¿¡å·
        self.guide_proj = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.GELU(),
            nn.LayerNorm(d_model)
        )

        self.fusion_proj = nn.Sequential(
            nn.Linear(d_model * 2, d_model),
            nn.GELU(),
            nn.LayerNorm(d_model)
        )

        self.gamma = nn.Parameter(torch.ones(1, 1, d_model) * 1e-3) if use_layerscale else None

        self.feedforward = nn.Sequential(
            nn.Linear(d_model, d_model * 2),
            nn.GELU(),
            nn.Linear(d_model * 2, d_model)
        )

        self.debug_counter = 0
        self.debug_every = 30  # æ¯ N æ¬¡æ‰“å°ä¸€æ¬¡
        self.debug_flag = False
    def forward(self, x):  # x: (B, T, C)
        self.debug_counter += 1
        B, T, _ = x.size()

        # Pre-LN ä¿è¯ Attention è¾“å…¥ç‰¹å¾å¹³ç¨³ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§
        x_norm1 = self.norm1(x)

        if self.causal:
            attn_mask = torch.triu(torch.ones(T, T, device=x.device), diagonal=1).bool()
        else:
            attn_mask = None  # çœ‹å…¨å±€
        # attn_out(1,256,128)  attn_weights:(1,256,256)
        attn_out, attn_weights = self.attn(x_norm1, x_norm1, x_norm1, attn_mask=attn_mask)

        # attn_weights:(1,256,256) x_norm1(1,256,128) batch matrix multiply æ‰¹é‡çŸ©é˜µä¹˜æ³•
        query_summary = torch.bmm(attn_weights, x_norm1)  # (1,256,128)
        gate = torch.sigmoid(self.guide_proj(query_summary))  # æ§åˆ¶è°ƒåˆ¶å¼ºåº¦

        x_tcn = self.tcn(x)
        x_tcn = x_tcn * (1 + gate)

        fusion = torch.cat([x_tcn, attn_out], dim=-1)  # (B, T, 2C)
        fusion = self.fusion_proj(fusion)  # â†’ (B, T, C)

        if self.gamma is not None:
            fusion = self.gamma * fusion  # æ§åˆ¶èåˆåçš„è¡¨è¾¾å¼ºåº¦
        fusion_norm = self.norm2(fusion)
        # å‰é¦ˆç¥ç»ç½‘ç»œå­å±‚ æå‡ç‰¹å¾è¡¨è¾¾èƒ½åŠ›ï¼Œå¢åŠ ç‰¹å¾äº¤äº’ï¼ŒåŠ æ·±ç½‘ç»œçš„éçº¿æ€§å»ºæ¨¡èƒ½åŠ›
        # FFN æ˜¯æµ…å±‚å¢å¼ºï¼Œä¸è´Ÿè´£é‡å»ºå¤æ‚å…¨å±€ä¾èµ–ï¼Œæ®‹å·®å¸®åŠ©èåˆä¸Šä¸‹æ–‡å’Œå±€éƒ¨å¢å¼ºä¿¡æ¯ã€‚
        out = self.feedforward(fusion_norm) + fusion
        return out

############################################# ä¸»å¹²ç½‘ç»œ ##############################################
class STDA_Net(nn.Module):
    def __init__(self, in_channels=4, num_classes=5, base_filters=64, dropout=0.3):
        super().__init__()

        self.spectral_enhancement = Spectral_Enhancement(num_channels = in_channels)

        self.dams_cnn = DAMS_CNN(in_channels = in_channels)

        # Use Hybrid TCN+Transformer
        self.agle = AGLE(
            d_model=100,
            dropout=0.2,
            n_heads=5,
            causal=False
        )

        self.classifier = nn.Sequential(
            nn.Linear(100, 256),
            nn.LayerNorm(256),
            nn.GELU(),
            nn.Dropout(0.2),

            nn.Linear(256, 128),
            nn.LayerNorm(128),
            nn.GELU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )

        self.global_pool = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten()
        )

        self.feature_norm = nn.LayerNorm(128)

    def forward(self, data, labels, criterion=None):

        spec_data = self.spectral_enhancement(data)

        features = self.dams_cnn(spec_data)  # [B, 128, 8, 8]

        pooled = self.global_pool(features)  # [B, 128]

        feat_encoded = self.agle(pooled.unsqueeze(0)).squeeze(0)

        logits = self.classifier(feat_encoded)

        if criterion is not None and labels is not None:
            ce_loss = criterion(logits, labels)
        else:
            ce_loss = torch.tensor(0.0, device=logits.device)
        return {'logits': logits, 'total_loss': ce_loss, 'features': feat_encoded}
